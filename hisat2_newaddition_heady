#!/bin/bash
 
######### FunGen Course Instructions ############
## Purpose: The purpose of this script is to 
##    Use HiSat2 to index your reference genome and then map your cleaned (paired) reads to the indexed reference
##              First need to use gffread to convert annotation file from .gff3 to .gft formate
##              Use Stringtie to count the reads mapped to genes and transcripts, defined in this case by the genome annotation file
##              use the python script to take the Stringtie results to make two counts matricies, one at the gene level and one at the transcript level
## HiSat2  Indexing   InPut: Reference genome file (.fasta), and annotation file (.gff3) (Optional)
##                    Output: Indexed genome 
## HiSat2 Mapping     Input: Cleaned read files, paired (.fasq); Indexed genome
##                    Output: Alignment .sam files  
## Samtools  Convert .sam to .bam and sort          Input: Alignment files,  .sam
##                                                  Output: Sorted  .bam files
## Stringtie  Counting reads  Input: sorted .bam file
##                            Output:  Directories of counts files for Ballgown (R program for DGE)
##              prepDE.py    Python script to create a counts matrics from the Stringtie output.  Inputs: Directory from Stringtie
##                                                                                                Output:  .csv files of counts matrix
## For running the script on the Alabama Super Computer.
##  For more information: https://hpcdocs.asc.edu/content/slurm-queue-system
##  After you have this script in your home directory and you have made it executable using  "chmod +x [script name]", 
#  then run the script by using "run_script [script name]"
##  suggested paramenters are below to submit this script.
##    queue: large
##    core: 12
##    time limit (HH:MM:SS): 18:00:00 
##    Memory: 120gb
##    
###############################################

#### Load all the programs you are going to use in this script.
source /apps/profiles/modules_asax.sh.dyn
module load hisat2/2.2.0
module load stringtie/2.2.1
module load gcc/9.4.0
module load python/3.10.8-zimemtc
module load samtools
module load bcftools
module load gffread
module load sra
#module load gffcompare


#  Set the stack size to unlimited
#ulimit -s unlimited


# Turn echo on so all commands are echoed in the output log
set -x

##########  Define variables and make directories
## Replace the numbers in the brackets with Your specific information
  ## make variable for your ASC ID so the directories are automatically made in YOUR directory
  ## Replace the [#] with paths to define these variable
#MyID= aubclsc0321          ## Example: MyID=aubtss

WD=/scratch/aubclsc0321/PracticeRNAseq2
DD= /scratch/aubclsc0321/PracticeRNAseq2/RawData2            ## Example:/scratch/$MyID/PracticeRNAseq  
CD=/scratch/aubclsc0321/PracticeRNAseq2/CleanData2            ## Example:/scratch/$MyID/PracticeRNAseq/CleanData   #   *** This is where the cleaned paired files are located $
REFD=/scratch/AMPHIBIAN24/XTropicalisRefGenome           ## Example:/scratch/$MyID/PracticeRNAseq/DaphniaRefGenome    # this directory contains the indexed reference genome$
MAPD=/scratch/aubclsc0321/PracticeRNAseq2/Map_HiSat2.2           ## Example:/scratch/$MyID/PracticeRNAseq/Map_HiSat2      #
COUNTSD=/scratch/aubclsc0321/PracticeRNAseq2/Counts_StringTie2	   ## Example:/scratch/$MyID/PracticeRNAseq/Counts_StringTie
RESULTSD=/home/aubclsc0321/PracticeRNAseq2/Counts_H_S_2024.2      ## Example:/home/aubtss/PracticeRNAseq/Counts_H_S

RDQ= /scratch/aubclsc0321/PracticeRNAseq2/RawDataQuality2
RCQ= /scratch/aubclsc0321/PracticeRNAseq2/RawCleanQuality2
adapters=TrueSpe3-PE-2.fa  

REF=UCB_Xtro_10.0                  ## This is what the "easy name" will be for the genome reference

## Make the directories and all subdirectories defined by the variables above
mkdir -p $REFD
mkdir -p $MAPD
mkdir -p $COUNTSD
mkdir -p $RESULTSD
mkdir -p $WD
mkdir -p $DD

#Download data files from NCBI:###

#fasterq-dump --split-files DRR316901
#fasterq-dump --split-files DRR316902
#fasterq-dump --split-files DRR316903
#fasterq-dump --split-files DRR316904
#fasterq-dump --split-files DRR316905
#fasterq-dump --split-files DRR316906

#FASTQC to assess qulaity of the sequence data# 
#mkdir ${WD}/${RDQ}
#fastqc *.fastq --outdir=${WD}/${RDQ}

##MutliQC to summarized the fastqc results! 
#cd ${WD}/${RDQ}
#multiqc ${WD}/${RDQ}

###Tarball the directory containing the FASTQC and MultiQC results to we can easily bring  it back###
#tar cvzf ${RDQ}.tar.gz ${WD}/${RDQ}/*


### cleaning  the data with Trimmomatic ###
#mkdir ${CD}
#mkdir ${WD}/${PCQ}

#move to Raw Data Directory
#cd ${DD}


#make list of file names to Trim 
#ls | grep ".fastq" |cut -d "_" -f 1 | sort | uniq > list

### Copy over the list of Sequencing Adapters that we want Trimmomatic to look for 
#cp /home/aubclsc0321/TruSeq3-PE-2.fa . 


##Run a while loop to proceses through the names in the list and Trim  them with the Trimmomatic Code 
#while read i 
#do 

#fastqc ${CD}/"$i"_1_paired.fastq --outdir=${WD}/${PCQ}
#fastqc ${CD}/"$i"_2_paired.fastq --outdir=${WD}/${PCQ}

#don<list  #this is the end of the loop 

#Run MULTIQC to sumarize the faastqc results 
####move to directory with the cleanded data
#cd ${WD}/${PCQ}
#multiqc ${WD}/${PCQ}


################ Now compress your results files from the qulaity Assessment by FASTQC##
###Tarball the directory containing the FASTQC results so we can easily bring it back to our computer###
#tar cvzf ${PCQ}.tar.gz ${WD}/${PCQ}/* 



##################  Prepare the Reference Index for mapping with HiSat2   #############################
cd $REFD
### Copy the reference genome (.fasta) and the annotation file (.gff3) to this REFD directory
#cp  /scratch/AMPHIBIAN24/reference_data/ncbi_dataset/data/GCF_017654675.1/GCF_017654675.1_Xenopus_laevis_v10.1_genomic.fna . 
#cp  /scratach/AMPHIBIAN24/refernce_data/ncbi_dataset/data/GCF_017654675.1/genomic.gff .

###  Identify exons and splice sites on the reference genome
#gffread ${REF}.gff3 -T -o ${REF}.gtf               ## gffread converts the annotation file from .gff3 to .gft formate for HiSat2 to use.
#hisat2_extract_splice_sites.py ${REF}.gtf > ${REF}.ss
#hisat2_extract_exons.py ${REF}.gtf > ${REF}.exon

#### Create a HISAT2 index for the reference genome. NOTE every mapping program will need to build a its own index.
hisat2-build --ss ${REF}.ss --exon ${REF}.exon ${REF}.fasta AMPHIBIAN24_index

########################  Map and Count the Data using HiSAT2 and StringTie  ########################

# Move to the data directory
cd ${CD}  #### This is where our clean paired reads are located.

## Create list of fastq files to map.    Example file format of your cleaned reads file names: SRR629651_1_paired.fastq SRR629651_2_paired.fastq
## grab all fastq files, cut on the underscore, use only the first of the cuts, sort, use unique put in list
ls | grep ".fastq" |cut -d "_" -f 1| sort | uniq > list    #should list Example: SRR629651

## Move to the directory for mapping
cd ${MAPD}

## move the list of unique ids from the original files to map
mv ${CD}/list  . 

## process the samples in the list, one by one using a while loop
while read i;
do
  ## HiSat2 is the mapping program
  ##  -p indicates number of processors, --dta reports alignments for StringTie --rf is the read orientation
   hisat2 -p 16 --min-intronlen <50> --dta --phred33       \
    -x "${REFD}"/AMPHIBIAN24_index	 \
    -1 "${CD}"/"$i"_1_paired.fastq  -2 "${CD}"/"$i"_2_paired.fastq	\
    -S "$i".sam

    ### view: convert the SAM file into a BAM file  -bS: BAM is the binary format corresponding to the SAM text format.
    ### sort: convert the BAM file to a sorted BAM file.
    ### Example Input: SRR629651.sam; Output: SRR629651_sorted.bam
  samtools view -@ 6 -bS "$i".sam > "$i".bam  

    ###  This is sorting the bam, using 6 threads, and producing a .bam file that includes the word 'sorted' in the name
    samtools sort -@ 6  "$i".bam  -o  "$i"_sorted.bam

    ### Index the BAM and get mapping statistics, and put them in a text file for us to look at.
  samtools flagstat   "$i"_sorted.bam   > "$i"_Stats.txt

  ### Stringtie is the program that counts the reads that are mapped to each gene, exon, transcript model. 
  ### The output from StringTie are counts folders in a directory that is ready to bring into the R program Ballgown to 
  ### Original: This will make transcripts using the reference geneome as a guide for each sorted.bam
  ### eAB options: This will run stringtie once and  ONLY use the Ref annotation for counting readsto genes and exons 

	###COUNTING####  

	mkdir "${COUNTSD}"/"$i"
	stringtie -p 6 -e -B -G  "${REFD}"/"${REF}".gtf -o "${COUNTSD}"/"$i"/"$i".gtf -l "$i"   "${MAPD}"/"$i"_sorted.bam

done<list

#####################  Copy Results to home Directory.  These will be the files you want to bring back to your computer.
### these are your stats files from Samtools
cp *.txt ${RESULTSD}

### The prepDE.py is a python script that converts the files in your ballgown folder to a count matrix. 
 ## Move to the counts directory
cd ${COUNTSD}
 ## run the python script prepDE.phy to prepare you data for downstream analysis.
cp /home/aubclsc0321/class_shared/prepDE.py3 .

 prepDE.py3 -i ${COUNTSD}

### copy the final results files (the count matricies that are .cvs) to your home directory. 
cp *.csv ${RESULTSD}
## move these results files to your personal computer for downstream statistical analyses in R studio.
